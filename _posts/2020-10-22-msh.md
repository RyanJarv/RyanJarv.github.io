---
layout: post
title: Bridging the gap between code and serverless
---

{{ page.title }}
================

<p class="meta">22 November 2020 - Somewhere</p>

Sometime ago I started a project called [coderun](https://github.com/RyanJarv/coderun) it was meant to make running code in docker containers and lambda stupid easy and secure. I kinda left it in a half finished state because I wasn't sure where I wanted to take the project.

It was a bit over engineered but the idea was you could simply start the shell and execute any script and it would pull down the right container and run the code. It even had fancy plugins that acted like little snitch as well as FuseFS mounts for intercepting calls to sensitive files, allowing you to accept or block access. All though these where quite interesting, I think the the more interesting part of the project is treating code, docker, and lambda the same, wrapped in a shell you know all to well.

i.e if you run ./test.py in this shell will deploy and run it in docker the same as it would in lambda (if it was running in the lambda mode).


Of course docker and lambda are not the same thing though.. maybe I should have started with an ECS mode here instead. But anyways, I'll think about that another time. What I want to try to figure out is how can we seamlessly bridge local and remote resources in a way that is as simple as possible. The rest of this post is mostly just going to be a collection of notes more than anything.


### Shell
```
shell  > ./first.sh
````

Self explanatory, first.sh always executes, sometimes-second.sh executes if the first fails and always-third.sh executes every-time at the end.

### Docker
```
> ./first.sh
```

We can do the same in docker fairly simply either by making our own shell which tries to dynamically determine what the docker image we should be. This is what I attempted to do with [coderun](https://github.com/RyanJarv/coderun).


### Docker with shell syntax

```
> ./first.sh && ./sometimes-second.sh; always-third.sh
```

 A way simpler way to do what I tried to do above can be done using [jessfraz's setup](https://github.com/jessfraz/dockerfiles). It also just run's in the normal shell, so nothing special going on here for &&, ;, etc...


### lambda

```
./first.sh
```

[coderun](https://github.com/RyanJarv/coderun) also attempted to do this in a similar way as the docker example.


### lambda with shell syntax

```
> ./first.sh && ./sometimes-second.sh; always-third.sh
```

Using event machine we can define a fair bit of shell scripts. I've messed around a bit with this but lost my notes on it, but either way though I'll likely be coming back to this. We should be able to do stdin/out/err piping here as well.

## Tying it all together

I think this is the big question that I need to think about more.

* All of this should be shell native ([coderun](https://github.com/RyanJarv/coderun) is a mess).
  * A simple shell to event machine compiler will likely be desirable still (allows for separate security roles/domains/etc..)
* All environments should *seem* like they are running on the local system
  * optionally sharing a remote filesystem
  * stdin/stdout/stderr with pipes and the terminal should act as expected
  * Signals can be handled through event bridge if needed
  * this may be possible by passing metadata through envvars, or local sockets while keeping high bandwidth data in the environment belongs
    * remote stdin/stdout/stderr fifo's should be quick to create (amazonmq?)
* All environments should be interoperable
  * An ecs function should be-able to pipe to a local cmd back to a function



